# -*- coding: utf-8 -*-
"""ParkinsonTelemonitoring.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19DFxyU9GZtG6XJe0pyJ-5FP5amxF0Q1k
"""

from google.colab import drive
drive.mount("gdrive")

"""##Importing the necessary libraries."""

import pandas as pd 
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

from sklearn.preprocessing import StandardScaler,MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier,ExtraTreeRegressor
from sklearn.linear_model import Ridge,Lasso,ElasticNet,RidgeCV,LassoCV,ElasticNetCV
import tensorflow as tf

"""## Read the dataset."""

df = pd.read_csv("/content/gdrive/My Drive/DataAnalysis/Parkinson/parkinsons_updrs.data")

df.head()

"""##Metadata regarding on the dataset."""

df.describe()

df.info()

df.isnull().sum()

"""There is no null instance in the dataset which is a very good thing since we can continue on the EDA."""

fig, ax = plt.subplots(1,1)
df["motor_UPDRS"].plot(kind="density")
df["total_UPDRS"].plot(kind="density")
fig.show()

fig, ax = plt.subplots(figsize=(15,12))         # Sample figsize in inches
sns.heatmap(df.drop(columns=["subject#"]).corr(), annot=True, linewidths=.5,ax=ax, fmt= '.1f',mask= np.triu(np.ones_like(df.drop(columns=["subject#"]).corr(), dtype=np.bool)))

"""Gender is a parameter on the voices of the individuals,we will analyze them separately."""

sns.countplot(df.sex.value_counts())
plt.title("Female vs Male")
plt.show()

from itertools import combinations
def scatter_patient(df, subject_list, columns, patient_filter, scatter_alpha=0.3):
    fig, ax = plt.subplots(figsize=(30,22))
    f = [comb for comb in combinations(range(len(columns)), 2)]
    
    for _, fp, _ in patient_filter:
        fp = fp & subject_list
        
    for i in range(len(f)):
        plt.subplot(5,5,i + 1)
        column_1 = columns[f[i][0]]
        column_2 = columns[f[i][1]]
        
        for name, fp, color in patient_filter:
            plt.scatter(df[fp][column_1], df[fp][column_2], alpha=scatter_alpha, marker='.', color=color, s=5, label=name)
        
        plt.xlabel(column_1)
        plt.ylabel(column_2)
        if(i == 0 or i == len(f)):
            plt.legend(markerscale=5, framealpha=1)


sex_filter_patient = [('Male', df['sex'] == 0, 'red'), 
                      ('Female', df['sex'] == 1, 'black')]
scatter_patient(df, df['subject#'] == df['subject#'], ['NHR', 'HNR', 'PPE', 'DFA', 'RPDE'], sex_filter_patient)

low_margin = 66
less = df['age'] <= low_margin
more = df['age'] > low_margin

age_filter_patient = [('Age<{}'.format(low_margin), less, 'green'), 
                      ('{}>Age'.format(low_margin), more, 'black')]
scatter_patient(df, True, ['NHR', 'HNR', 'PPE', 'DFA', 'RPDE'], age_filter_patient, scatter_alpha=0.3)

"""## Preprocessing"""

scaler = StandardScaler()
non_cat = df.drop(columns=["sex"])
cat = df[["sex"]]
non_cat = pd.DataFrame(scaler.fit_transform(non_cat),columns=non_cat.columns)
non_cat["sex"] = cat

features = non_cat.drop(columns=["subject#","motor_UPDRS","total_UPDRS"])
target = df[["motor_UPDRS","total_UPDRS"]]
X_train,X_test,y_train,y_test = train_test_split(features,target,test_size=0.50,random_state=42)

"""##Model Selection"""

from sklearn.ensemble import RandomForestRegressor

rfr = RandomForestRegressor()
rfr.fit(X_train,y_train)
r2_score(y_test,rfr.predict(X_test))

mean_squared_error(y_test,rfr.predict(X_test))

X_train.columns.shape
forest.feature_importances_.shape

forest = ExtraTreeRegressor()
forest.fit(X_train,y_train)
importances = forest.feature_importances_

indices = np.argsort(importances)[::-1]

# Print the feature ranking
print("Feature ranking:")

for f in range(X_train.shape[1]):
    print("%d. feature %d (%f)" % (f + 1, indices[f], importances[indices[f]]))

# Plot the impurity-based feature importances of the forest
plt.figure()
plt.title("Feature importances")
plt.bar(range(X_train.shape[1]), importances[indices],
        color="r",  align="center")
plt.xticks(range(X_train.shape[1]), indices)
plt.xlim([-1, X_train.shape[1]])
plt.show()

X_train.drop(X_train.columns[indices[-12:]],axis=1,inplace=True)

X_train.head()

X_test.drop(X_test.columns[indices[-12:]],axis=1,inplace=True)

rfr = RandomForestRegressor()
rfr.fit(X_train,y_train)

r2_score(y_test,rfr.predict(X_test))