{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pokemon.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EkRUPdhAIms",
        "colab_type": "text"
      },
      "source": [
        "# Pokemon Type Classification using Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXqTsXHkAF9V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "183fb94e-e95e-414a-f5fa-576b7219b0d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"gdrive\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at gdrive; to attempt to forcibly remount, call drive.mount(\"gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mth1g_LAfjq",
        "colab_type": "text"
      },
      "source": [
        "##Import necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeTz2ZMEAjlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from shutil import copyfile, copy2,rmtree\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from sklearn.metrics import RocCurveDisplay,classification_report,confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krqq5eKvA_qe",
        "colab_type": "text"
      },
      "source": [
        "## Read the structured data regarding on the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDLOpiN1A--l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/gdrive/My Drive/DataAnalysis/Pokemon/pokemon.csv\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-Mo388wBSAN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "e5532896-9045-41db-961d-0e50a9d54377"
      },
      "source": [
        "df.head(-1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Type1</th>\n",
              "      <th>Type2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bulbasaur</td>\n",
              "      <td>Grass</td>\n",
              "      <td>Poison</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ivysaur</td>\n",
              "      <td>Grass</td>\n",
              "      <td>Poison</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>venusaur</td>\n",
              "      <td>Grass</td>\n",
              "      <td>Poison</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>charmander</td>\n",
              "      <td>Fire</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>charmeleon</td>\n",
              "      <td>Fire</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>naganadel</td>\n",
              "      <td>Poison</td>\n",
              "      <td>Dragon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804</th>\n",
              "      <td>stakataka</td>\n",
              "      <td>Rock</td>\n",
              "      <td>Steel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>blacephalon</td>\n",
              "      <td>Fire</td>\n",
              "      <td>Ghost</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806</th>\n",
              "      <td>zeraora</td>\n",
              "      <td>Electric</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>807</th>\n",
              "      <td>meltan</td>\n",
              "      <td>Steel</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>808 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Name     Type1   Type2\n",
              "0      bulbasaur     Grass  Poison\n",
              "1        ivysaur     Grass  Poison\n",
              "2       venusaur     Grass  Poison\n",
              "3     charmander      Fire     NaN\n",
              "4     charmeleon      Fire     NaN\n",
              "..           ...       ...     ...\n",
              "803    naganadel    Poison  Dragon\n",
              "804    stakataka      Rock   Steel\n",
              "805  blacephalon      Fire   Ghost\n",
              "806      zeraora  Electric     NaN\n",
              "807       meltan     Steel     NaN\n",
              "\n",
              "[808 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw0K2yqFBYbw",
        "colab_type": "text"
      },
      "source": [
        "As we Pokemon fans know some pokemons only contain one Type which can be a little problematic for some built-in models that we are going to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urDYEAvgCGyA",
        "colab_type": "text"
      },
      "source": [
        "Let's get filenames regarding on the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L-u2CHoHFlu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "0bed97e3-d3ef-45ed-970d-96af08c3d9a7"
      },
      "source": [
        "DIR_IMAGE = \"/content/gdrive/My Drive/DataAnalysis/Pokemon/images/images\" \n",
        "FILEs=[] \n",
        "for file in listdir(DIR_IMAGE): \n",
        "  if(isfile(join(DIR_IMAGE,file))): \n",
        "    FILEs.append(file)\n",
        "df[\"images\"] = pd.Series()\n",
        "new = pd.DataFrame()\n",
        "for FILE in FILEs:\n",
        "  POK_NAME = FILE[:-4]\n",
        "  df.loc[df['Name'] == POK_NAME,\"images\"]=FILE\n",
        "df.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Type1</th>\n",
              "      <th>Type2</th>\n",
              "      <th>images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bulbasaur</td>\n",
              "      <td>Grass</td>\n",
              "      <td>Poison</td>\n",
              "      <td>bulbasaur.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ivysaur</td>\n",
              "      <td>Grass</td>\n",
              "      <td>Poison</td>\n",
              "      <td>ivysaur.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>venusaur</td>\n",
              "      <td>Grass</td>\n",
              "      <td>Poison</td>\n",
              "      <td>venusaur.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>charmander</td>\n",
              "      <td>Fire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>charmander.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>charmeleon</td>\n",
              "      <td>Fire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>charmeleon.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Name  Type1   Type2          images\n",
              "0   bulbasaur  Grass  Poison   bulbasaur.png\n",
              "1     ivysaur  Grass  Poison     ivysaur.png\n",
              "2    venusaur  Grass  Poison    venusaur.png\n",
              "3  charmander   Fire     NaN  charmander.png\n",
              "4  charmeleon   Fire     NaN  charmeleon.png"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpP79eOybSrq",
        "colab_type": "text"
      },
      "source": [
        "### Distribution of pokemons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKXQ06-qbYLZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "0da8f0c4-a260-4fd5-bb7e-8ac151c2db07"
      },
      "source": [
        "fig = plt.figure(figsize=(15,6))\n",
        "ax=sns.countplot(df.Type1,data=df)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rzSoptqgwRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "select = ['Water' , 'Grass']\n",
        "df = df[df['Type1'].isin(select)]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvcFfM0FctrM",
        "colab_type": "text"
      },
      "source": [
        "Let's first try to evaluate on Water and Grass pokemons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQrPCoGzIL9y",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ITyDEo5dPhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rmtree('train/')\n",
        "rmtree('test/')\n",
        "rmtree('val/')\n",
        "os.makedirs('/content/gdrive/My Drive/DataAnalysis/Pokemon/train/',exist_ok=True)\n",
        "os.makedirs('/content/gdrive/My Drive/DataAnalysis/Pokemon/test/',exist_ok=True)\n",
        "os.makedirs('/content/gdrive/My Drive/DataAnalysis/Pokemon/val/',exist_ok=True)\n",
        "for class_ in df['Type1'].unique():\n",
        "    os.makedirs('train/'+str(class_)+'/',exist_ok=True)\n",
        "    os.makedirs('test/'+str(class_)+'/',exist_ok=True)\n",
        "    os.makedirs('val/'+str(class_)+'/',exist_ok=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTI4yAfcIEO-",
        "colab_type": "text"
      },
      "source": [
        "Directories for test,train and val data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJjEQH7vevDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df, df['Type1'],test_size=0.33, stratify=df['Type1'],random_state=42)\n",
        "\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.33,stratify=y_test)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9uBQJvuhdjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image,type_  in zip(X_train['images'], y_train):\n",
        "    copy2(join(DIR_IMAGE,image), 'train/'+type_)\n",
        "\n",
        "for image,type_ in zip(X_test['images'], y_test):\n",
        "    copy2(join(DIR_IMAGE,image), 'test/'+type_)\n",
        "\n",
        "for image,type_ in zip(X_val['images'], y_val):\n",
        "    copy2(join(DIR_IMAGE,image), 'val/'+type_)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0qTabTHm3R5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e4dfd8f6-46bc-498e-c690-1569279780de"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator()\n",
        "\n",
        "train = datagen.flow_from_directory('train/')\n",
        "test = datagen.flow_from_directory('test/')\n",
        "val = datagen.flow_from_directory('val/')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 128 images belonging to 2 classes.\n",
            "Found 42 images belonging to 2 classes.\n",
            "Found 22 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of_EhInRISwy",
        "colab_type": "text"
      },
      "source": [
        "## Swiss Knife:Resnet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NJtKeG3umso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#resnet50\n",
        "resnet50 = tf.keras.applications.ResNet50(\n",
        "    include_top=False, weights='imagenet',input_shape= (256,256,3)\n",
        ")\n",
        "for layer in resnet50.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSUcg8Xb7ZOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x = resnet50.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.7)(x)\n",
        "predictions = tf.keras.layers.Dense(2, activation= 'softmax')(x)\n",
        "model = tf.keras.Model(inputs = resnet50.input, outputs = predictions)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XikDk3s79Hq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC5omC9T8BEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "87f7f421-f5d2-4dc2-db00-1027623cca21"
      },
      "source": [
        "history = model.fit_generator(train,\n",
        "                              epochs=5,\n",
        "                              validation_data=val\n",
        "                             )"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "4/4 [==============================] - 27s 7s/step - loss: 1.5204 - accuracy: 0.5000 - val_loss: 0.8437 - val_accuracy: 0.5455\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 22s 6s/step - loss: 1.0697 - accuracy: 0.5938 - val_loss: 0.7640 - val_accuracy: 0.6364\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 22s 6s/step - loss: 0.9063 - accuracy: 0.6797 - val_loss: 0.6338 - val_accuracy: 0.6818\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 22s 6s/step - loss: 1.0709 - accuracy: 0.6016 - val_loss: 0.5624 - val_accuracy: 0.7273\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 23s 6s/step - loss: 0.9370 - accuracy: 0.5859 - val_loss: 0.5509 - val_accuracy: 0.6818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8uC3P1Iuck4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "556616f7-4b2d-4efa-a491-5ad41fdfe23b"
      },
      "source": [
        "predict_frame = pd.DataFrame([])\n",
        "predict = model.predict_generator(test)\n",
        "predict_frame['category'] = np.argmax(predict, axis=-1)\n",
        "labels = dict((v,k) for k,v in val.class_indices.items())\n",
        "predict_frame['category'] = predict_frame['category'].replace(labels)\n",
        "print(classification_report(y_test, predict_frame['category']))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Grass       0.60      0.18      0.27        17\n",
            "       Water       0.62      0.92      0.74        25\n",
            "\n",
            "    accuracy                           0.62        42\n",
            "   macro avg       0.61      0.55      0.51        42\n",
            "weighted avg       0.61      0.62      0.55        42\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKynuXMrIarM",
        "colab_type": "text"
      },
      "source": [
        "Channels regarding on the two distributed data causes the main problem since we can not evaluate a model just from their shapes(Pokemons do not allow us to create a discriminative model by their shapes so edges are not effective as colors).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDpWvcemJ3wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image,type_ in zip(X_val['images'], y_val):\n",
        "    copy2('val/'+type_+\"/\"+image,'train/'+type_)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYvfaQQSKTBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8274b7b2-2b3b-42ca-dc50-c7fa716acf63"
      },
      "source": [
        "train = datagen.flow_from_directory('train/')\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 150 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuaDdj75KXSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "c3e46064-9571-4f3d-92a6-f7fa644e36e7"
      },
      "source": [
        "history = model.fit_generator(train,\n",
        "                              epochs=5,\n",
        "                             )"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 22s 4s/step - loss: 0.9193 - accuracy: 0.6533\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 22s 4s/step - loss: 0.5825 - accuracy: 0.7400\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 22s 4s/step - loss: 0.6986 - accuracy: 0.6933\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.6592 - accuracy: 0.7333\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 22s 4s/step - loss: 0.5695 - accuracy: 0.7267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxXaKDLtLDqv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "5d596ca5-1e3a-4852-b56f-56aefd972b01"
      },
      "source": [
        "predict_frame = pd.DataFrame([])\n",
        "predict = model.predict_generator(test)\n",
        "predict_frame['category'] = np.argmax(predict, axis=-1)\n",
        "labels = dict((v,k) for k,v in val.class_indices.items())\n",
        "predict_frame['category'] = predict_frame['category'].replace(labels)\n",
        "print(classification_report(y_test, predict_frame['category']))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Grass       0.45      0.29      0.36        17\n",
            "       Water       0.61      0.76      0.68        25\n",
            "\n",
            "    accuracy                           0.57        42\n",
            "   macro avg       0.53      0.53      0.52        42\n",
            "weighted avg       0.55      0.57      0.55        42\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unalV5ceLKHw",
        "colab_type": "text"
      },
      "source": [
        "We are now able to correctly identify 2 pokemons max out of 3 pokemons and only for (Grass vs Fire)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUgPAs6eLqK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet152 = tf.keras.applications.ResNet152(\n",
        "    include_top=False, weights='imagenet',input_shape= (256,256,3)\n",
        ")\n",
        "for layer in resnet152.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRJ3ClUsLyBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = resnet152.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.7)(x)\n",
        "predictions = tf.keras.layers.Dense(2, activation= 'softmax')(x)\n",
        "model = tf.keras.Model(inputs = resnet152.input, outputs = predictions)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeCjtcKUL5J7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D_p4S8IL7Yt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "cd506a88-c2a3-4c91-9b21-979e4a84e292"
      },
      "source": [
        "history = model.fit_generator(train,\n",
        "                              epochs=5,\n",
        "                             )"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 62s 12s/step - loss: 0.7059 - accuracy: 0.7200\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 61s 12s/step - loss: 0.6646 - accuracy: 0.7400\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 66s 13s/step - loss: 0.5761 - accuracy: 0.7533\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 61s 12s/step - loss: 0.5318 - accuracy: 0.7733\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 61s 12s/step - loss: 0.7524 - accuracy: 0.6933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKM6Z4FgRbaL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "c39dd7e2-3575-44ac-db65-aac892e69804"
      },
      "source": [
        "predict_frame = pd.DataFrame([])\n",
        "predict = model.predict_generator(test)\n",
        "predict_frame['category'] = np.argmax(predict, axis=-1)\n",
        "labels = dict((v,k) for k,v in val.class_indices.items())\n",
        "predict_frame['category'] = predict_frame['category'].replace(labels)\n",
        "print(classification_report(y_test, predict_frame['category']))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Grass       0.89      0.47      0.62        17\n",
            "       Water       0.73      0.96      0.83        25\n",
            "\n",
            "    accuracy                           0.76        42\n",
            "   macro avg       0.81      0.72      0.72        42\n",
            "weighted avg       0.79      0.76      0.74        42\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWKk4PsqYl-A",
        "colab_type": "text"
      },
      "source": [
        "It was a cheap shot but was worth it.This notebook needs more work."
      ]
    }
  ]
}