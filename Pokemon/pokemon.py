# -*- coding: utf-8 -*-
"""Pokemon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZGqcP8Pdc0W7E-YP_BWQglaPo7_CwmNL

# Pokemon Type Classification using Image
"""

from google.colab import drive
drive.mount("gdrive")

"""##Import necessary libraries."""

import pandas as pd 
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from shutil import copyfile, copy2,rmtree


import tensorflow as tf
import cv2
import os
from os import listdir
from os.path import isfile, join
from sklearn.metrics import RocCurveDisplay,classification_report,confusion_matrix
from sklearn.model_selection import train_test_split

"""## Read the structured data regarding on the images."""

df = pd.read_csv("/content/gdrive/My Drive/DataAnalysis/Pokemon/pokemon.csv")

df.head(-1)

"""As we Pokemon fans know some pokemons only contain one Type which can be a little problematic for some built-in models that we are going to use.

Let's get filenames regarding on the images.
"""

DIR_IMAGE = "/content/gdrive/My Drive/DataAnalysis/Pokemon/images/images" 
FILEs=[] 
for file in listdir(DIR_IMAGE): 
  if(isfile(join(DIR_IMAGE,file))): 
    FILEs.append(file)
df["images"] = pd.Series()
new = pd.DataFrame()
for FILE in FILEs:
  POK_NAME = FILE[:-4]
  df.loc[df['Name'] == POK_NAME,"images"]=FILE
df.head()

"""### Distribution of pokemons."""

fig = plt.figure(figsize=(15,6))
ax=sns.countplot(df.Type1,data=df)

select = ['Water' , 'Grass']
df = df[df['Type1'].isin(select)]

"""Let's first try to evaluate on Water and Grass pokemons.

## Data Preprocessing
"""

rmtree('train/')
rmtree('test/')
rmtree('val/')
os.makedirs('/content/gdrive/My Drive/DataAnalysis/Pokemon/train/',exist_ok=True)
os.makedirs('/content/gdrive/My Drive/DataAnalysis/Pokemon/test/',exist_ok=True)
os.makedirs('/content/gdrive/My Drive/DataAnalysis/Pokemon/val/',exist_ok=True)
for class_ in df['Type1'].unique():
    os.makedirs('train/'+str(class_)+'/',exist_ok=True)
    os.makedirs('test/'+str(class_)+'/',exist_ok=True)
    os.makedirs('val/'+str(class_)+'/',exist_ok=True)

"""Directories for test,train and val data."""

X_train, X_test, y_train, y_test = train_test_split(
    df, df['Type1'],test_size=0.33, stratify=df['Type1'],random_state=42)

X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.33,stratify=y_test)

for image,type_  in zip(X_train['images'], y_train):
    copy2(join(DIR_IMAGE,image), 'train/'+type_)

for image,type_ in zip(X_test['images'], y_test):
    copy2(join(DIR_IMAGE,image), 'test/'+type_)

for image,type_ in zip(X_val['images'], y_val):
    copy2(join(DIR_IMAGE,image), 'val/'+type_)

from keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator()

train = datagen.flow_from_directory('train/')
test = datagen.flow_from_directory('test/')
val = datagen.flow_from_directory('val/')

"""## Swiss Knife:Resnet50"""

#resnet50
resnet50 = tf.keras.applications.ResNet50(
    include_top=False, weights='imagenet',input_shape= (256,256,3)
)
for layer in resnet50.layers:
    layer.trainable = False

x = resnet50.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dropout(0.7)(x)
predictions = tf.keras.layers.Dense(2, activation= 'softmax')(x)
model = tf.keras.Model(inputs = resnet50.input, outputs = predictions)

model.compile(loss='categorical_crossentropy',
              optimizer="adam",
              metrics=['accuracy'])

history = model.fit_generator(train,
                              epochs=5,
                              validation_data=val
                             )

predict_frame = pd.DataFrame([])
predict = model.predict_generator(test)
predict_frame['category'] = np.argmax(predict, axis=-1)
labels = dict((v,k) for k,v in val.class_indices.items())
predict_frame['category'] = predict_frame['category'].replace(labels)
print(classification_report(y_test, predict_frame['category']))

"""Channels regarding on the two distributed data causes the main problem since we can not evaluate a model just from their shapes(Pokemons do not allow us to create a discriminative model by their shapes so edges are not effective as colors)."""

for image,type_ in zip(X_val['images'], y_val):
    copy2('val/'+type_+"/"+image,'train/'+type_)

train = datagen.flow_from_directory('train/')

history = model.fit_generator(train,
                              epochs=5,
                             )

predict_frame = pd.DataFrame([])
predict = model.predict_generator(test)
predict_frame['category'] = np.argmax(predict, axis=-1)
labels = dict((v,k) for k,v in val.class_indices.items())
predict_frame['category'] = predict_frame['category'].replace(labels)
print(classification_report(y_test, predict_frame['category']))

"""We are now able to correctly identify 2 pokemons max out of 3 pokemons and only for (Grass vs Fire)."""

resnet152 = tf.keras.applications.ResNet152(
    include_top=False, weights='imagenet',input_shape= (256,256,3)
)
for layer in resnet152.layers:
    layer.trainable = False

x = resnet152.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dropout(0.7)(x)
predictions = tf.keras.layers.Dense(2, activation= 'softmax')(x)
model = tf.keras.Model(inputs = resnet152.input, outputs = predictions)

model.compile(loss='categorical_crossentropy',
              optimizer="adam",
              metrics=['accuracy'])

history = model.fit_generator(train,
                              epochs=5,
                             )

predict_frame = pd.DataFrame([])
predict = model.predict_generator(test)
predict_frame['category'] = np.argmax(predict, axis=-1)
labels = dict((v,k) for k,v in val.class_indices.items())
predict_frame['category'] = predict_frame['category'].replace(labels)
print(classification_report(y_test, predict_frame['category']))

"""It was a cheap shot but was worth it.This notebook needs more work."""