# -*- coding: utf-8 -*-
"""StudentPerformance.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LzD2k1J4iATUhd6S81RsO0H6odRwZJqI

#Student Performance Analysis
"""

from google.colab import drive
drive.mount("gdrive")

"""## Import the necessary libraries"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#ML Libraries and utils
from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error
from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler,StandardScaler
import tensorflow as tf

"""## Read the datasets."""

df_mat = pd.read_csv("/content/gdrive/My Drive/DataAnalysis/StudentPerformance/student-mat.csv",delimiter=";")
df_por = pd.read_csv("/content/gdrive/My Drive/DataAnalysis/StudentPerformance/student-por.csv",delimiter=";")

df_mat.head()

df_por.head()

"""## Metadata regarding on both datasets."""

df_mat.describe()

df_por.describe()

df_mat.info()

df_por.info()

def unique_categories(df):
  for col in df.columns:
    if(df[col].dtype=="object"):
      print(col,":",df[col].unique())

"""### Categorical Variables"""

print("DF MAT:")
unique_categories(df_mat)
print("\nDF POR:")
unique_categories(df_por)

"""## EDA

### School
"""

print("'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira")
f, (ax1, ax2) = plt.subplots(1, 2, sharey=True,figsize=(10,5))
ax1.set_title("Math")
sns.countplot(df_mat.school,data=df_mat,ax=ax1)
ax2.set_title("Portuguese")
sns.countplot(df_por.school,data=df_por,ax=ax2)
f.show()

"""### Sex"""

f, (ax1, ax2) = plt.subplots(1, 2, sharey=True,figsize=(10,5))
ax1.set_title("Math")
sns.countplot(df_mat.sex,data=df_mat,ax=ax1)
ax2.set_title("Portuguese")
sns.countplot(df_por.sex,data=df_por,ax=ax2)
f.show()

"""### Address"""

print(" 'U' - urban or 'R' - rural")
f, (ax1, ax2) = plt.subplots(1, 2, sharey=True,figsize=(10,5))
ax1.set_title("Math")
sns.countplot(df_mat.address,data=df_mat,ax=ax1)
ax2.set_title("Portuguese")
sns.countplot(df_por.address,data=df_por,ax=ax2)
f.show()

"""### Family size"""

print("'LE3' - less or equal to 3 or 'GT3' - greater than 3")
f, (ax1, ax2) = plt.subplots(1, 2, sharey=True,figsize=(10,5))
ax1.set_title("Math")
sns.countplot(df_mat.famsize,data=df_mat,ax=ax1)
ax2.set_title("Portuguese")
sns.countplot(df_por.famsize,data=df_por,ax=ax2)
f.show()

"""### Parents maritial status"""

print("'T' - living together or 'A' - apart")
f, (ax1, ax2) = plt.subplots(1, 2, sharey=True,figsize=(10,5))
ax1.set_title("Math")
sns.countplot(df_mat.Pstatus,data=df_mat,ax=ax1)
ax2.set_title("Portuguese")
sns.countplot(df_por.Pstatus,data=df_por,ax=ax2)
f.show()

"""### Father,Mother job ,reason to choose this school, student's guardian"""

f, ([ax1, ax2],[ax3,ax4],[ax5,ax6],[ax7,ax8]) = plt.subplots(4, 2, sharey=True,figsize=(10,20))
ax1.set_title("Math")
sns.countplot(df_mat.Mjob,data=df_mat,ax=ax1)
ax2.set_title("Portuguese")
sns.countplot(df_por.Mjob,data=df_por,ax=ax2)
sns.countplot(df_mat.Fjob,data=df_mat,ax=ax3)
sns.countplot(df_por.Fjob,data=df_por,ax=ax4)
sns.countplot(df_mat.reason,data=df_mat,ax=ax5)
sns.countplot(df_por.reason,data=df_por,ax=ax6)
sns.countplot(df_mat.guardian,data=df_mat,ax=ax7)
sns.countplot(df_por.guardian,data=df_por,ax=ax8)
f.show()

"""### Extra educational support (schoolsup),family educational support (famsup),extra paid classes within the course subject (paid),extra-curricular activities (activities)"""

f, ([ax1, ax2],[ax3,ax4],[ax5,ax6],[ax7,ax8]) = plt.subplots(4, 2, sharey=True,figsize=(10,20))
ax1.set_title("Math")
sns.countplot(df_mat.schoolsup,data=df_mat,ax=ax1,palette=["r","g"])
ax2.set_title("Portuguese")
sns.countplot(df_por.schoolsup,data=df_por,ax=ax2,palette=["r","g"])
sns.countplot(df_mat.famsup,data=df_mat,ax=ax3,palette=["r","g"])
sns.countplot(df_por.famsup,data=df_por,ax=ax4,palette=["r","g"])
sns.countplot(df_mat.paid,data=df_mat,ax=ax5,palette=["r","g"])
sns.countplot(df_por.paid,data=df_por,ax=ax6,palette=["r","g"])
sns.countplot(df_mat.activities,data=df_mat,ax=ax7,palette=["r","g"])
sns.countplot(df_por.activities,data=df_por,ax=ax8,palette=["r","g"])
f.show()

"""### Attended nursery school (nursery),wants to take higher education (higher),Internet access at home (internet),with a romantic relationship (romantic)"""

f, ([ax1, ax2],[ax3,ax4],[ax5,ax6],[ax7,ax8]) = plt.subplots(4, 2, sharey=True,figsize=(10,20))
ax1.set_title("Math")
sns.countplot(df_mat.nursery,data=df_mat,ax=ax1,palette=["r","b"])
ax2.set_title("Portuguese")
sns.countplot(df_por.nursery,data=df_por,ax=ax2,palette=["r","b"])
sns.countplot(df_mat.higher,data=df_mat,ax=ax3,palette=["r","b"])
sns.countplot(df_por.higher,data=df_por,ax=ax4,palette=["r","b"])
sns.countplot(df_mat.romantic,data=df_mat,ax=ax5,palette=["r","b"])
sns.countplot(df_por.romantic,data=df_por,ax=ax6,palette=["r","b"])
sns.countplot(df_mat.internet,data=df_mat,ax=ax7,palette=["r","b"])
sns.countplot(df_por.internet,data=df_por,ax=ax8,palette=["r","b"])
f.show()

"""### Correlation Matrix"""

fig, (ax1,ax2) = plt.subplots(1,2,figsize=(20,12))         # Sample figsize in inches
sns.heatmap(df_mat.corr(), annot=True, linewidths=.5,ax=ax1, fmt= '.1f',mask= np.triu(np.ones_like(df_mat.corr(), dtype=np.bool)))
sns.heatmap(df_por.corr(), annot=True, linewidths=.5,ax=ax2, fmt= '.1f',mask= np.triu(np.ones_like(df_por.corr(), dtype=np.bool)))

"""### Pairplot for continious variables"""

#g=sns.pairplot(df_mat.drop(columns=['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']))
#g.fig.set_size_inches(50,50)

"""## Data Preprocessing"""

features_mat = df_mat.drop(columns=["G1","G2","G3"])
target_mat = df_mat.G3

features_por = df_por.drop(columns=["G1","G2","G3"])
target_por = df_por.G3

features_mat = df_mat.drop(columns=["G1","G2","G3"],axis=1)
target_mat = df_mat.G3

features_por = df_por.drop(columns=["G1","G2","G3"])
target_por = df_por.G3

features_mat=features_mat.append(features_por,ignore_index=True)
target_mat=target_mat.append(target_por,ignore_index=True)

len(features_mat)

d = {range(0, 10): 0,range(10, 20): 1}

target_mat = target_mat.apply(lambda x: next((v for k, v in d.items() if x in k), 0))

features_mat = pd.get_dummies(features_mat)

standard = MinMaxScaler()
features_mat_ = pd.DataFrame(standard.fit_transform(features_mat.select_dtypes("int64")),columns=features_mat.select_dtypes("int64").columns)
for col in features_mat_.columns:
  features_mat[col] = features_mat_[col]

X_train,X_test,y_train,y_test = train_test_split(features_mat,target_mat,test_size=0.33,random_state=42)

X_train.head()

y_train.astype("category")

y_test.value_counts()

"""## Model Selection"""

print(X_train.shape)
model  = tf.keras.Sequential()
model.add(tf.keras.layers.Flatten(input_shape=(56,)))
model.add(tf.keras.layers.Dense(28,activation="swish"))
model.add(tf.keras.layers.Dense(7,activation="swish"))
model.add(tf.keras.layers.Dense(2,activation="softmax"))

model.compile(loss="binary_crossentropy",optimizer="adam",metrics=["accuracy"])
model.summary()

y_train=tf.keras.utils.to_categorical(y_train,2)
history = model.fit(X_train,y_train,epochs=30)

from sklearn.metrics import classification_report
print(classification_report(y_test,model.predict_classes(X_test)))

from sklearn.metrics import confusion_matrix

con = confusion_matrix(y_test,model.predict_classes(X_test))
sns.heatmap(con)